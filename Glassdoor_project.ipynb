{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [
        "vncDsAP0Gaoa",
        "FJNUwmbgGyua",
        "w6K7xa23Elo4",
        "yQaldy8SH6Dl",
        "mDgbUHAGgjLW",
        "O_i_v8NEhb9l",
        "HhfV-JJviCcP",
        "Y3lxredqlCYt",
        "3RnN4peoiCZX",
        "x71ZqKXriCWQ",
        "7hBIi_osiCS2",
        "JlHwYmJAmNHm",
        "35m5QtbWiB9F",
        "PoPl-ycgm1ru",
        "H0kj-8xxnORC",
        "nA9Y7ga8ng1Z",
        "PBTbrJXOngz2",
        "u3PMJOP6ngxN",
        "dauF4eBmngu3",
        "bKJF3rekwFvQ",
        "MSa1f5Uengrz",
        "GF8Ens_Soomf",
        "0wOQAZs5pc--",
        "K5QZ13OEpz2H",
        "lQ7QKXXCp7Bj",
        "448CDAPjqfQr",
        "KSlN3yHqYklG",
        "t6dVpIINYklI",
        "ijmpgYnKYklI",
        "-JiQyfWJYklI",
        "EM7whBJCYoAo",
        "fge-S5ZAYoAp",
        "85gYPyotYoAp",
        "RoGjAbkUYoAp",
        "4Of9eVA-YrdM",
        "iky9q4vBYrdO",
        "F6T5p64dYrdO",
        "y-Ehk30pYrdP",
        "bamQiAODYuh1",
        "QHF8YVU7Yuh3",
        "GwzvFGzlYuh3",
        "qYpmQ266Yuh3",
        "OH-pJp9IphqM",
        "bbFf2-_FphqN",
        "_ouA3fa0phqN",
        "Seke61FWphqN",
        "PIIx-8_IphqN",
        "t27r6nlMphqO",
        "r2jJGEOYphqO",
        "b0JNsNcRphqO",
        "BZR9WyysphqO",
        "jj7wYXLtphqO",
        "eZrbJ2SmphqO",
        "rFu4xreNphqO",
        "YJ55k-q6phqO",
        "gCFgpxoyphqP",
        "OVtJsKN_phqQ",
        "lssrdh5qphqQ",
        "U2RJ9gkRphqQ",
        "1M8mcRywphqQ",
        "tgIPom80phqQ",
        "JMzcOPDDphqR",
        "x-EpHcCOp1ci",
        "X_VqEhTip1ck",
        "8zGJKyg5p1ck",
        "PVzmfK_Ep1ck",
        "n3dbpmDWp1ck",
        "ylSl6qgtp1ck",
        "ZWILFDl5p1ck",
        "M7G43BXep1ck",
        "Ag9LCva-p1cl",
        "E6MkPsBcp1cl",
        "2cELzS2fp1cl",
        "3MPXvC8up1cl",
        "NC_X3p0fY2L0",
        "UV0SzAkaZNRQ",
        "YPEH6qLeZNRQ",
        "q29F0dvdveiT",
        "EXh0U9oCveiU",
        "22aHeOlLveiV",
        "g-ATYxFrGrvw",
        "Yfr_Vlr8HBkt",
        "8yEUt7NnHlrM",
        "tEA2Xm5dHt1r",
        "I79__PHVH19G",
        "Ou-I18pAyIpj",
        "fF3858GYyt-u",
        "4_0_7-oCpUZd",
        "hwyV_J3ipUZe",
        "3yB-zSqbpUZe",
        "dEUvejAfpUZe",
        "Fd15vwWVpUZf",
        "bn_IUdTipZyH",
        "49K5P_iCpZyH",
        "Nff-vKELpZyI",
        "kLW572S8pZyI",
        "dWbDXHzopZyI",
        "yLjJCtPM0KBk",
        "xiyOF9F70UgQ",
        "7wuGOrhz0itI",
        "id1riN9m0vUs",
        "578E2V7j08f6",
        "89xtkJwZ18nB",
        "67NQN5KX2AMe",
        "Iwf50b-R2tYG",
        "GMQiZwjn3iu7",
        "WVIkgGqN3qsr",
        "XkPnILGE3zoT",
        "Hlsf0x5436Go",
        "mT9DMSJo4nBL",
        "c49ITxTc407N",
        "OeJFEK0N496M",
        "9ExmJH0g5HBk",
        "cJNqERVU536h",
        "k5UmGsbsOxih",
        "T0VqWOYE6DLQ",
        "qBMux9mC6MCf",
        "-oLEiFgy-5Pf",
        "C74aWNz2AliB",
        "2DejudWSA-a0",
        "pEMng2IbBLp7",
        "rAdphbQ9Bhjc",
        "TNVZ9zx19K6k",
        "nqoHp30x9hH9",
        "rMDnDkt2B6du",
        "yiiVWRdJDDil",
        "1UUpS68QDMuG",
        "kexQrXU-DjzY",
        "T5CmagL3EC8N",
        "BhH2vgX9EjGr",
        "qjKvONjwE8ra",
        "P1XJ9OREExlT",
        "VFOzZv6IFROw",
        "TIqpNgepFxVj",
        "VfCC591jGiD4",
        "OB4l2ZhMeS1U",
        "ArJBuiUVfxKd",
        "4qY1EAkEfxKe",
        "PiV4Ypx8fxKe",
        "TfvqoZmBfxKf",
        "dJ2tPlVmpsJ0",
        "JWYfwnehpsJ1",
        "-jK_YjpMpsJ2",
        "HAih1iBOpsJ2",
        "zVGeBEFhpsJ2",
        "bmKjuQ-FpsJ3",
        "Fze-IPXLpx6K",
        "7AN1z2sKpx6M",
        "9PIHJqyupx6M",
        "_-qAgymDpx6N",
        "Z-hykwinpx6N",
        "h_CCil-SKHpo",
        "cBFFvTBNJzUa",
        "HvGl1hHyA_VK",
        "EyNgTHvd2WFk",
        "KH5McJBi2d8v",
        "iW_Lq9qf2h6X",
        "-Kee-DAl2viO",
        "gCX9965dhzqZ",
        "gIfDvo9L0UH2"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/diyanali/Glassdoor_salaryPrediction/blob/main/Glassdoor_project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Project Name**    - Glassdoor Salary Prediction\n",
        "\n"
      ],
      "metadata": {
        "id": "vncDsAP0Gaoa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### **Project Type**    - Regression\n",
        "##### **Contribution**    - Individual\n"
      ],
      "metadata": {
        "id": "beRrZCGUAJYm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Project Summary -**"
      ],
      "metadata": {
        "id": "FJNUwmbgGyua"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In today’s rapidly evolving job market, understanding and estimating fair compensation has become increasingly important for both job seekers and employers. Salary transparency not only helps candidates make informed decisions but also assists companies in offering competitive pay structures. This project focuses on leveraging machine learning techniques to build a model capable of predicting salary estimates for job postings using data collected from Glassdoor, one of the leading platforms for job listings and company reviews.\n",
        "\n",
        "The primary objective of this project is to develop a supervised regression model that can predict the salary range for a given job description. The model will utilize various job and company-related features such as job title, company rating, location, size, industry, and required skills to determine an appropriate salary estimate. This type of problem falls under the category of supervised learning, specifically a regression task, where the target variable is a continuous numerical value representing the salary estimate.\n",
        "\n",
        "The dataset for this project includes detailed job postings from Glassdoor, consisting of features like company name, job title, location, headquarters, rating, size, industry, sector, revenue, and more. Additionally, certain binary indicators such as whether the job description mentions Python, Excel, AWS, or Spark are included to capture technical skill requirements. Some fields, such as salary estimates and job descriptions, require parsing and preprocessing to extract meaningful features like seniority level or job function.\n",
        "\n",
        "The real-world utility of this project lies in its wide range of applications. Job seekers can use the model’s predictions to gauge whether a posted salary aligns with market standards, reducing the risk of underpayment or missed opportunities. Employers and HR professionals can use the insights to set competitive salaries for attracting top talent. Moreover, educational counselors and career platforms can integrate such models to guide students and professionals with data-driven career planning.\n",
        "\n",
        "To build the predictive model, the first step involves thorough data cleaning and preprocessing. This includes handling missing or inconsistent values, encoding categorical variables into a machine-readable format, and scaling numerical features where necessary. Exploratory data analysis (EDA) is then performed to identify patterns, correlations, and outliers that could affect model performance.\n",
        "\n",
        "Several regression algorithms will be evaluated for this task, including Linear Regression as a baseline model, and more sophisticated approaches like Decision Trees, Random Forest Regressors, and XGBoost. These models will be assessed using common regression metrics such as Mean Absolute Error (MAE), Mean Squared Error (MSE), Root Mean Squared Error (RMSE), and the R² Score to determine how well the model captures the variability in salary predictions. Hyperparameter tuning using GridSearchCV or RandomizedSearchCV may also be performed to enhance model performance.\n",
        "\n",
        "Optionally, the project can be extended to include a user interface using frameworks like Streamlit or Flask, allowing users to input job features and receive instant salary predictions. This makes the model accessible and interactive, increasing its usability in real-world scenarios.\n",
        "\n",
        "In conclusion, the Glassdoor Salary Prediction project is a practical and impactful application of machine learning in the domain of career analytics and HR tech. It combines data preprocessing, feature engineering, model building, and evaluation into a comprehensive pipeline that can empower individuals and organizations with actionable salary insights.\n",
        "\n"
      ],
      "metadata": {
        "id": "F6v_1wHtG2nS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **GitHub Link -**"
      ],
      "metadata": {
        "id": "w6K7xa23Elo4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://github.com/diyanali/Glassdoor_salaryPrediction"
      ],
      "metadata": {
        "id": "h1o69JH3Eqqn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Problem Statement**\n"
      ],
      "metadata": {
        "id": "yQaldy8SH6Dl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Develop a machine learning model to predict job salary estimates based on company and job-related features using data from Glassdoor.\n"
      ],
      "metadata": {
        "id": "DpeJGUA3kjGy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***Let's Begin !***"
      ],
      "metadata": {
        "id": "O_i_v8NEhb9l"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***1. Know Your Data***"
      ],
      "metadata": {
        "id": "HhfV-JJviCcP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Import Libraries"
      ],
      "metadata": {
        "id": "Y3lxredqlCYt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
        "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from xgboost import XGBRegressor\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "plt.style.use('ggplot')\n",
        "sns.set_palette('Set2')"
      ],
      "metadata": {
        "id": "M8Vqi-pPk-HR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Loading"
      ],
      "metadata": {
        "id": "3RnN4peoiCZX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df=pd.read_csv('glassdoor_jobs.csv')"
      ],
      "metadata": {
        "id": "4CkvbW_SlZ_R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset First View"
      ],
      "metadata": {
        "id": "x71ZqKXriCWQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "id": "LWNFOSvLl09H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Rows & Columns count"
      ],
      "metadata": {
        "id": "7hBIi_osiCS2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.shape"
      ],
      "metadata": {
        "id": "Kllu7SJgmLij"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Information"
      ],
      "metadata": {
        "id": "JlHwYmJAmNHm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()"
      ],
      "metadata": {
        "id": "e9hRXRi6meOf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Duplicate Values"
      ],
      "metadata": {
        "id": "35m5QtbWiB9F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "duplicate_count =df.duplicated().sum()\n",
        "print(\"Number of duplicate rows:\", duplicate_count)"
      ],
      "metadata": {
        "id": "1sLdpKYkmox0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.apply(lambda col: col.duplicated().sum()) ##no. of duplicate values in each column\n"
      ],
      "metadata": {
        "id": "WF24DXZPfxF1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Missing Values/Null Values"
      ],
      "metadata": {
        "id": "PoPl-ycgm1ru"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.drop(['Unnamed: 0'],axis=1,inplace=True)"
      ],
      "metadata": {
        "id": "rY0vXJIPgLKU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9f05e6a5-21f4-4752-9589-797949396112"
      },
      "outputs": [],
      "source": [
        "df['Company Name'] = df['Company Name'].str.split('\\n').str[0]#Removing'/n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3d3d404e-1290-4994-98f1-3d5b7cb984ef"
      },
      "outputs": [],
      "source": [
        "df['Min Salary']=df.apply(lambda row: row['Salary Estimate'][:row['Salary Estimate'].find('-')], axis=1)#Min Salary Column"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "35bfa218-3acd-4aaa-a13c-2df0a6e9e8f2"
      },
      "outputs": [],
      "source": [
        "df['Min Salary'] = df.apply(\n",
        "    lambda row: row['Min Salary'][row['Min Salary'].find(':') + 1:].strip()\n",
        "    if row['Min Salary'].startswith('Employer Provided Salary:')\n",
        "    else row['Min Salary'],\n",
        "    axis=1\n",
        ")#Min Salry Creation In Specific Cases"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fd46e2f6-c76f-44c9-ab3e-7ba2b373b93c"
      },
      "outputs": [],
      "source": [
        "for i in range(len(df)):\n",
        "    if df.iloc[i]['Salary Estimate'].endswith('(Glassdoor est.)'):\n",
        "        salary_est = df.iloc[i]['Salary Estimate']\n",
        "        start = salary_est.find('-') + 1\n",
        "        end = salary_est.find(' ')\n",
        "        df.at[i, 'Max Salary'] = salary_est[start:end]\n",
        "\n",
        "    elif df.iloc[i]['Salary Estimate'].endswith('(Employer est.)'):\n",
        "        salary_est = df.iloc[i]['Salary Estimate']\n",
        "        start = salary_est.find('-') + 1\n",
        "        end = salary_est.find('(')\n",
        "        df.at[i, 'Max Salary'] = salary_est[start:end]\n",
        "\n",
        "    elif df.iloc[i]['Salary Estimate'].startswith('Employer Provided Salary:') and df.iloc[i]['Salary Estimate'].endswith('Per Hour'):\n",
        "        salary_est = df.iloc[i]['Salary Estimate']\n",
        "        salary_range = salary_est.replace('Employer Provided Salary:', '').replace('Per Hour', '').strip()\n",
        "        min_sal, max_sal = salary_range.split('-')\n",
        "        df.at[i, 'Max Salary'] = max_sal.strip()\n",
        "\n",
        "\n",
        "    elif df.iloc[i]['Salary Estimate'].startswith('Employer Provided Salary:'):\n",
        "        salary_est = df.iloc[i]['Salary Estimate']\n",
        "        start = salary_est.find('-') + 1\n",
        "        df.at[i, 'Max Salary'] = salary_est[start:]\n",
        "\n",
        "    #Creation Of Max Salary using specific conditions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5e7346a1-1eaf-47ac-99ea-c3fb1b0c6f7f"
      },
      "outputs": [],
      "source": [
        "df['Max Salary']=df['Max Salary'].replace(np.nan,'')\n",
        "#Replacing '' with null"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2a39d6d2-db48-46f0-a20d-799af9b54114"
      },
      "outputs": [],
      "source": [
        "def parse_salary(s):\n",
        "    s = s.strip().replace('$', '')\n",
        "    if s.endswith('K'):\n",
        "        return int(float(s.replace('K', '')))  # Annual salary\n",
        "    else:\n",
        "        hourly = float(s)\n",
        "        return int((hourly * 40 * 52)/1000)  # Convert hourly to annual assuming 40 hrs/week\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f8df52e0-51e5-4afa-83a1-f392516f0fe7"
      },
      "outputs": [],
      "source": [
        "df['Max Salary'] = df[df['Max Salary']!='']['Max Salary'].apply(parse_salary)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "38dae016-70d6-4743-a6af-e47dacbd6f1c"
      },
      "outputs": [],
      "source": [
        "df['Min Salary'] = df[df['Min Salary']!='']['Min Salary'].apply(parse_salary)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c2645eaf-3f49-4ae2-92ad-fdd8e3d3c051"
      },
      "outputs": [],
      "source": [
        "df['Avg Salary']=np.round((df['Max Salary']+df['Min Salary'])/2,decimals=2)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Maximum,minimum and average Salary are created."
      ],
      "metadata": {
        "id": "h2mJjrPMhik7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### What did you know about your dataset?"
      ],
      "metadata": {
        "id": "H0kj-8xxnORC"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8ca3cde6-9fc4-4f61-829f-5fc30ffe43bc"
      },
      "outputs": [],
      "source": [
        "df.drop(['Salary Estimate'],axis=1,inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6872dc4d-9a19-4a9c-bdbd-840ae635a0c2"
      },
      "outputs": [],
      "source": [
        "df.drop(['Job Description'],axis=1,inplace=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Salary estimation and job description columns are eliminated."
      ],
      "metadata": {
        "id": "sESy3HpViA8c"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d07e27cd-6de4-431c-a459-200327958b60"
      },
      "outputs": [],
      "source": [
        "df['Rating']=df['Rating'].replace(-1,np.nan)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "28fa7d70-2e39-4c43-bbea-45ea318cd2ba"
      },
      "outputs": [],
      "source": [
        "df['Company Name']=df['Company Name'].replace('<intent>',np.nan)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "missing values are replaced with null values"
      ],
      "metadata": {
        "id": "G09LFB46iYkK"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "513c44e1-57a6-4564-b713-afc53cafe8f5"
      },
      "outputs": [],
      "source": [
        "df['Location_State'] = df['Location'].apply(\n",
        "    lambda x: x[x.find(',')+2:].strip() if ',' in x else x.strip()\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7e359eb2-7b15-4f18-8b24-75f05d386151"
      },
      "outputs": [],
      "source": [
        "df.drop(['Location'],axis=1,inplace=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "new column Location state is created to store on state name."
      ],
      "metadata": {
        "id": "bBTm_z3Jik-8"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cf2795b9-bacc-4576-8ef7-2b5ee660e370"
      },
      "outputs": [],
      "source": [
        "df['Headquarters'] = df['Headquarters'].apply(\n",
        "    lambda x: x[x.find(',')+2:].strip() if ',' in x else x.strip()\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b9248eee-efa4-4771-9829-7e6a90721049"
      },
      "outputs": [],
      "source": [
        "df['Headquarters']=df['Headquarters'].replace('-1',np.nan)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8bc8f094-6e2d-4e2f-b158-556f7f1efe55"
      },
      "outputs": [],
      "source": [
        "df['Size']=df['Size'].replace('-1',np.nan)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "845e089b-20de-4818-ad3b-a6c3fd81f5ab"
      },
      "outputs": [],
      "source": [
        "df['Founded']=df['Founded'].replace(-1,np.nan)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dfd49ec0-f75f-4cc0-a4ba-d7b5d58cae8f"
      },
      "outputs": [],
      "source": [
        "df['Type of ownership']=df['Type of ownership'].replace('-1',np.nan)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b103c3c1-12f7-4568-a815-b6456abe53d2"
      },
      "outputs": [],
      "source": [
        "df['Industry']=df['Industry'].replace('-1',np.nan)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "02ab7105-b646-4e83-b0cd-0e90a9269a42"
      },
      "outputs": [],
      "source": [
        "df['Sector']=df['Sector'].replace('-1',np.nan)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9f33fa00-bf8f-4ce3-8978-9e00699c66f0"
      },
      "outputs": [],
      "source": [
        "df['Revenue']=df['Revenue'].replace('-1',np.nan)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "201de10f-874b-4054-b5d4-d3f35e1da2f0"
      },
      "outputs": [],
      "source": [
        "df['Competitors']=df['Competitors'].replace('-1',np.nan)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a08fe51d-9e1d-4055-8f8b-f3d63284a508"
      },
      "outputs": [],
      "source": [
        "df.drop(['Industry'],axis=1,inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "569b85fe-40b6-4639-82b6-58d4e37662bb"
      },
      "outputs": [],
      "source": [
        "df.isnull().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f24dbb33-c253-4b0c-9a9d-efc622d26431"
      },
      "outputs": [],
      "source": [
        "missing_percent = df.isnull().mean() * 100\n",
        "print(missing_percent.sort_values(ascending=False))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2c0482f3-c041-43fc-83d1-1cdcc0cd25ad"
      },
      "outputs": [],
      "source": [
        "missing = df.isnull().sum()\n",
        "missing = missing[missing > 0].sort_values(ascending=False)\n",
        "\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(10,6))\n",
        "sns.barplot(x=missing.values, y=missing.index, palette='mako')\n",
        "plt.xlabel(\"Number of Missing Values\")\n",
        "plt.ylabel(\"Columns\")\n",
        "plt.title(\"Missing Values Per Column\")\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f10c7041-051e-4749-9592-185ca014983f"
      },
      "outputs": [],
      "source": [
        "df.drop(['Competitors'],axis=1,inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7c974003-33dd-4fad-9115-5200d251b942"
      },
      "outputs": [],
      "source": [
        "df['Rating']=df['Rating'].replace(np.nan,df['Rating'].mean())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ea56e1ba-b865-44f0-a4f7-33e4704ca025"
      },
      "outputs": [],
      "source": [
        "categorical_cols = ['Company Name', 'Headquarters', 'Size', 'Type of ownership', 'Sector', 'Revenue']\n",
        "df[categorical_cols] = df[categorical_cols].fillna('Unknown')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "28849805-d756-4d5f-b650-ecc97bfc625f"
      },
      "outputs": [],
      "source": [
        "df['Founded'] = df['Founded'].fillna(df['Founded'].median())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "adeebdcd-86ec-4285-9bc5-b6f6ad570e86"
      },
      "outputs": [],
      "source": [
        "def clean_job_title(title):\n",
        "    title = title.lower()\n",
        "    if 'data scientist' in title:\n",
        "        return 'Data Scientist'\n",
        "    elif 'data analyst' in title:\n",
        "        return 'Data Analyst'\n",
        "    elif 'data engineer' in title:\n",
        "        return 'Data Engineer'\n",
        "    elif 'machine learning' in title or 'ml engineer' in title:\n",
        "        return 'ML Engineer'\n",
        "    elif 'research scientist' in title or 'researcher' in title:\n",
        "        return 'Research Scientist'\n",
        "    elif 'manager' in title or 'director' in title or 'lead' in title or 'head' in title:\n",
        "        return 'Manager/Director'\n",
        "    elif 'intern' in title or 'junior' in title or 'jr.' in title or 'college' in title:\n",
        "        return 'Intern/Junior'\n",
        "    elif 'analyst' in title:\n",
        "        return 'Other Analyst'\n",
        "    elif 'scientist' in title:\n",
        "        return 'Other Scientist'\n",
        "    else:\n",
        "        return 'Other'\n",
        "df['Cleaned Job Title'] = df['Job Title'].apply(clean_job_title)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f572f6ea-b9d5-4e73-a854-de3741804784"
      },
      "outputs": [],
      "source": [
        "def categorize_other_roles(title):\n",
        "    title = title.lower()\n",
        "\n",
        "    if any(k in title for k in ['chief', 'vp', 'head', 'director', 'principal']):\n",
        "        return 'Manager/Director'\n",
        "\n",
        "    elif 'consultant' in title or 'analytics consultant' in title:\n",
        "        return 'Other Analyst'\n",
        "\n",
        "    elif 'architect' in title or 'data modeler' in title:\n",
        "        return 'Other Scientist'\n",
        "\n",
        "    elif 'engineer' in title and any(k in title for k in ['product', 'platform', 'spark', 'systems']):\n",
        "        return 'Data Engineer'\n",
        "\n",
        "    elif 'analytics' in title or 'data systems specialist' in title or 'data & analytics' in title:\n",
        "        return 'Other Analyst'\n",
        "\n",
        "    elif 'data science engineer' in title or 'ml' in title:\n",
        "        return 'ML Engineer'\n",
        "\n",
        "    elif any(k in title for k in ['account exec', 'business development']):\n",
        "        return 'Manager/Director'\n",
        "\n",
        "    elif 'environmental' in title:\n",
        "        return 'Other Scientist'\n",
        "\n",
        "    elif 'intern' in title or 'junior' in title:\n",
        "        return 'Intern/Junior'\n",
        "\n",
        "    elif 'software engineer' in title and 'visualization' in title:\n",
        "        return 'Data Engineer'\n",
        "\n",
        "    elif 'product engineer' in title and 'data science' in title:\n",
        "        return 'Data Engineer'\n",
        "\n",
        "    elif 'data management specialist' in title:\n",
        "        return 'Data Analyst'\n",
        "\n",
        "    else:\n",
        "        return 'Other'\n",
        "df.loc[df['Cleaned Job Title'] == 'Other', 'Cleaned Job Title'] = \\\n",
        "    df.loc[df['Cleaned Job Title'] == 'Other', 'Job Title'].apply(categorize_other_roles)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "97e57eca-eba1-40b2-8595-058596a86d49"
      },
      "outputs": [],
      "source": [
        "df[df['Cleaned Job Title']=='Other']['Job Title']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6f351f10-e334-4bff-ae91-5b561422a6bf"
      },
      "outputs": [],
      "source": [
        "df.at[496, 'Cleaned Job Title'] = 'Data Scientist'\n",
        "df.at[746, 'Cleaned Job Title'] = 'Data Scientist'\n",
        "df.at[821, 'Cleaned Job Title'] = 'Data Scientist'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0017453d-fd2c-4267-a098-e1ae33fad7fc"
      },
      "outputs": [],
      "source": [
        "df.drop(['Job Title'],axis=1,inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "id": "nKzTPTc0n1cT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***2. Understanding Your Variables***"
      ],
      "metadata": {
        "id": "nA9Y7ga8ng1Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "list(df.columns)"
      ],
      "metadata": {
        "id": "j7xfkqrt5Ag5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.describe()"
      ],
      "metadata": {
        "id": "DnOaZdaE5Q5t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.dtypes"
      ],
      "metadata": {
        "id": "OaEk38JbEtXI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Check Unique Values for each variable."
      ],
      "metadata": {
        "id": "u3PMJOP6ngxN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for column in df.columns:\n",
        "    print(f\"\\n{column} - {df[column].nunique()} unique values\")\n",
        "    print(df[column].unique()[:10])  # Show only first 10 unique values\n"
      ],
      "metadata": {
        "id": "zms12Yq5n-jE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***4. Data Vizualization, Storytelling & Experimenting with charts : Understand the relationships between variables***"
      ],
      "metadata": {
        "id": "GF8Ens_Soomf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Univariate Histogram for Salary distribution"
      ],
      "metadata": {
        "id": "0wOQAZs5pc--"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sns.histplot(df['Avg Salary'], kde=True)\n",
        "plt.title(\"Salary Distribution\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "7v_ESjsspbW7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Box plot of Average Salary to spot outliers."
      ],
      "metadata": {
        "id": "PphbyryumQWc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sns.boxplot(x=df['Avg Salary'])\n",
        "plt.title(\"Boxplot of Average Salary\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "MyH44NrVmJu3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Box plot of slaary Distribution by Job title."
      ],
      "metadata": {
        "id": "XKhfYJH6nGvx"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "248969c6-144c-4b55-9616-d42af0fc1f4a"
      },
      "outputs": [],
      "source": [
        "sns.boxplot(data=df, x='Cleaned Job Title', y='Avg Salary')\n",
        "plt.xticks(rotation=45)\n",
        "plt.title(\"Salary Distribution by Job Title (In Thousands)\")\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "072a0e2c-742c-4d8c-9215-3b73dee26844"
      },
      "outputs": [],
      "source": [
        "df_filtered = df[df[\"Size\"] != 'Unknown']\n",
        "g = sns.FacetGrid(df_filtered, col='Size', col_wrap=3, height=4, sharex=False)\n",
        "g.map(sns.histplot, 'Avg Salary', kde=True, color='skyblue')\n",
        "g.set_titles(col_template=\"{col_name}\")\n",
        "g.fig.subplots_adjust(top=0.9)\n",
        "g.fig.suptitle(\"Histogram of Avg Salary by Company Size\", fontsize=16)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Data Preprocessing"
      ],
      "metadata": {
        "id": "L_unve4qsTZN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_data=df[df['Min Salary'].notna()]"
      ],
      "metadata": {
        "id": "hwmMb-nsom3j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_data=df[df['Min Salary'].notna()]"
      ],
      "metadata": {
        "id": "sEk7jJhnsiqo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data.head()"
      ],
      "metadata": {
        "id": "_Wz3ONqcsinW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_data.head()\n"
      ],
      "metadata": {
        "id": "-i_du5cTsijv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define target variable\n",
        "y = train_data['Min Salary']  # 'train' already has no NaNs in min_salary\n",
        "\n",
        "# Define feature set by dropping target and irrelevant columns\n",
        "X = train_data.drop(['Min Salary', 'Max Salary', 'Avg Salary', 'Salary Estimate',\n",
        "                'Job Title', 'Company Name', 'Job Description'],\n",
        "               axis=1, errors='ignore')\n"
      ],
      "metadata": {
        "id": "JM6mTFtPtsxm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42)\n"
      ],
      "metadata": {
        "id": "-WLT9p6RtLge"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from xgboost import XGBRegressor\n",
        "\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# Dictionary to store model results\n",
        "results = []\n",
        "\n",
        "# List of regression models to test\n",
        "models = {\n",
        "    'Linear Regression': LinearRegression(),\n",
        "    'Ridge Regression': Ridge(alpha=1.0),\n",
        "    'Lasso Regression': Lasso(alpha=0.1),\n",
        "    'Decision Tree': DecisionTreeRegressor(random_state=42),\n",
        "    'Random Forest': RandomForestRegressor(n_estimators=100, random_state=42),\n",
        "    'XGBoost': XGBRegressor(n_estimators=100, random_state=42, objective='reg:squarederror') # corrected objective\n",
        "}\n",
        "\n",
        "# Apply one-hot encoding to categorical features\n",
        "X_encoded = pd.get_dummies(X)\n",
        "\n",
        "# Train and evaluate each model\n",
        "for name, model in models.items():\n",
        "    # Use the encoded features X_encoded for training and prediction\n",
        "    model.fit(X_encoded, y)\n",
        "    # Need to apply the same encoding to X_test before predicting\n",
        "    # To do this properly, we should fit the OneHotEncoder on the training data (X_train)\n",
        "    # and then transform both X_train and X_test.\n",
        "    # Since we are fitting on X here, we will get dummy variables for all categories present in X\n",
        "    # and then apply this to X_test. This might lead to issues if X_test has categories not in X.\n",
        "    # A more robust approach would be to encode X_train and X_test separately after the split,\n",
        "    # ensuring consistent columns.\n",
        "\n",
        "    # For now, let's encode X_test using the columns from X_encoded\n",
        "    X_test_encoded = pd.get_dummies(X_test)\n",
        "    # Align columns - this is crucial if X_test has different categories than X\n",
        "    X_test_encoded = X_test_encoded.reindex(columns=X_encoded.columns, fill_value=0)\n",
        "\n",
        "\n",
        "    y_pred = model.predict(X_test_encoded)\n",
        "\n",
        "    mae = mean_absolute_error(y_test, y_pred)\n",
        "    mse = mean_squared_error(y_test, y_pred)\n",
        "    rmse = np.sqrt(mse)\n",
        "    r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "    results.append({\n",
        "        'Model': name,\n",
        "        'R² Score': round(r2, 4),\n",
        "        'MAE': round(mae, 2),\n",
        "        'MSE': round(mse, 2),\n",
        "        'RMSE': round(rmse, 2)\n",
        "    })\n",
        "\n",
        "# Convert results to a DataFrame for easy comparison\n",
        "results_df = pd.DataFrame(results)\n",
        "results_df.sort_values(by='R² Score', ascending=False, inplace=True)\n",
        "\n",
        "# Display the results\n",
        "print(results_df)"
      ],
      "metadata": {
        "id": "2dhUaaG9siUR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Conclusion\n",
        "The project successfully built and evaluated several machine learning models to predict job salary estimates based on the Glassdoor dataset. Through data cleaning, preprocessing, and exploratory analysis, the dataset was prepared for modeling. The evaluation of different regression algorithms revealed that the Decision Tree model provided the most accurate predictions for the minimum salary based on the features used. This suggests that a tree-based approach is effective in capturing the complex relationships between job and company features and salary estimates in this dataset. The developed model can be a valuable tool for job seekers and employers to understand and estimate salary ranges."
      ],
      "metadata": {
        "id": "JTX40zCQu9J-"
      }
    }
  ]
}